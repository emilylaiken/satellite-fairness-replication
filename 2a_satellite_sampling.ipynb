{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. Satellite Featurizations Part 1 - Obtaining Tile Geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILES_FOLDER = '/data/mosaiks/replication/sampled_tiles/'\n",
    "SHAPEFILES_FOLDER = '/data/mosaiks/shapefiles/'\n",
    "MAX_TILES_PER_REGION = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR US\n",
    "SHAPEFILE_FNAME = SHAPEFILES_FOLDER + 'us_pumas/pumas.shp'\n",
    "SHAPEFILE_IDS = ['State', 'PUMA']\n",
    "DATA_OUTFOLDER = TILES_FOLDER + 'us/'\n",
    "PLOTS_OUTFOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR MEXICO\n",
    "SHAPEFILE_FNAME = '/data/mosaiks/shapefiles/mexico_municipalities.geojson'\n",
    "SHAPEFILE_IDS = ['municipality']\n",
    "DATA_OUTFOLDER = TILES_FOLDER + 'mexico/'\n",
    "PLOTS_OUTFOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR INDIA\n",
    "# Esther TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR DHS COUNTRIES\n",
    "dhs_country = 'peru' # change 'colombia' to each DHS country\n",
    "SHAPEFILE_FNAME = '/data/mosaiks/surveys/dhs/' + dhs_country + '_polygons.geojson'\n",
    "SHAPEFILE_IDS = ['cluster']\n",
    "DATA_OUTFOLDER = TILES_FOLDER + 'dhs/' + dhs_country + '/' \n",
    "PLOTS_OUTFOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in shapefile and format\n",
    "shapefile = gpd.read_file(SHAPEFILE_FNAME)\n",
    "shapefile = shapefile.to_crs(epsg=4326)\n",
    "shapefile['bounds'] = shapefile['geometry'].apply(lambda x: x.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done gridding!...\n"
     ]
    }
   ],
   "source": [
    "# Get sampled MOSAIKS tiles for each region in the shapefile, along with degree of overlap\n",
    "num_eligible_squares = []\n",
    "num_used_squares = []\n",
    "tiles = []\n",
    "plot = False\n",
    "start = time.time()\n",
    "for i in range(len(shapefile)):\n",
    "    \n",
    "    print(('%.2f' % (100*i/len(shapefile))) + '% gridded...', end='\\r')\n",
    "    \n",
    "    # Get the region\n",
    "    region = shapefile.iloc[i]\n",
    "    region_info = gpd.GeoDataFrame(pd.DataFrame(region).T)\n",
    "    \n",
    "    # Get the bounding box for the region\n",
    "    min_latitude, max_latitude = region['bounds'][1], region['bounds'][3]\n",
    "    min_longitude, max_longitude = region['bounds'][0], region['bounds'][2]\n",
    "    \n",
    "    # Define the latitude/longitude grid of centroids\n",
    "    latitude_grid = (np.arange(round(min_latitude, 2)-.02, round(max_latitude, 2)+.02, .01) - .005)\n",
    "    longitude_grid = (np.arange(round(min_longitude, 2)-.02, round(max_longitude, 2)+.02, .01) - .005)\n",
    "    grid = np.meshgrid(latitude_grid, longitude_grid)\n",
    "    grid = np.array([grid[0].flatten(), grid[1].flatten()])\n",
    "    grid = pd.DataFrame(grid).T\n",
    "    grid.columns = ['Latitude', 'Longitude']\n",
    "    grid = gpd.GeoDataFrame(grid, geometry=gpd.points_from_xy(grid['Longitude'], grid['Latitude']), crs=4326)\n",
    "    \n",
    "    # Turn centroids into squares\n",
    "    squares = grid.copy()\n",
    "    squares['geometry'] = squares['geometry'].buffer(.005, cap_style=3)\n",
    "    \n",
    "    # Determine squares that have some overlap with the region\n",
    "    eligible_squares = gpd.sjoin(squares, region_info, how='inner', op='intersects')\n",
    "    num_eligible_squares.append(len(eligible_squares))\n",
    "    \n",
    "    # If more squares overlap with PUMA than we can process, take UAR sample of overlapping squares\n",
    "    if len(eligible_squares) > MAX_TILES_PER_REGION:\n",
    "        sampled_tiles = eligible_squares.sample(n=MAX_TILES_PER_REGION, replace=False, random_state=1)\n",
    "    else:\n",
    "        sampled_tiles = eligible_squares.copy()\n",
    "    \n",
    "    # Get weight for each tile (degree of overlap)\n",
    "    sampled_tiles['weight'] = sampled_tiles['geometry']\\\n",
    "        .apply(lambda x: 100*region['geometry'].buffer(0).intersection(x).area/x.area)\n",
    "    sampled_tiles = sampled_tiles.dropna(how='any')\n",
    "    \n",
    "    num_used_squares.append(len(sampled_tiles))\n",
    "    \n",
    "    # Write to file\n",
    "    sampled_tiles[['Latitude', 'Longitude', 'weight'] + SHAPEFILE_IDS]\\\n",
    "        .to_csv(DATA_OUTFOLDER + '/' + '_'.join([str(region[key]) for key in SHAPEFILE_IDS]), index=False)\n",
    "    \n",
    "    if PLOTS_OUTFOLDER is not None:\n",
    "        fig, ax = plt.subplots(1, figsize=(20, 20))\n",
    "        region_info.plot(ax=ax)\n",
    "        grid.plot(ax=ax, color='black', markersize=4)\n",
    "        squares.plot(ax=ax, color='lightgrey', alpha=.1, edgecolor='black')\n",
    "        eligible_squares.plot(ax=ax, color='grey', alpha=.3, edgecolor=None)\n",
    "        sampled_tiles.plot(ax=ax, color='grey', alpha=.5, edgecolor=None)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(' '.join([str(region[key]) for key in SHAPEFILE_IDS]), fontsize='xx-large')\n",
    "        plt.savefig(PLOTS_OUTFOLDER + '/' + '_'.join([str(region[key]) for key in SHAPEFILE_IDS]), dpi=300)\n",
    "\n",
    "print('Done gridding!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all tiles together, write to files partitioned for MOSAIKS API\n",
    "tiles = []\n",
    "for fname in os.listdir(DATA_OUTFOLDER):\n",
    "    if fname[0] != '.':\n",
    "        tiles.append(pd.read_csv(DATA_OUTFOLDER + '/' + fname))\n",
    "tiles = pd.concat(tiles)\n",
    "tiles = tiles[['Latitude', 'Longitude', 'weight'] + SHAPEFILE_IDS]\n",
    "tiles.to_csv(DATA_OUTFOLDER + '/sampled_tiles.csv', index=False, float_format='%.3f')\n",
    "tiles_with_duplicates = pd.read_csv(DATA_OUTFOLDER + '/sampled_tiles.csv')\n",
    "tiles = tiles_with_duplicates.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "partitions = list(np.arange(0, len(tiles), 100000)) + [len(tiles)]\n",
    "for i in range(len(partitions)-1):\n",
    "    tiles[partitions[i]:partitions[i+1]]\\\n",
    "        .to_csv(DATA_OUTFOLDER + 'sampled_tiles_partition_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum eligible tiles: 12.00 (New York 3803)\n",
      "Maximum eligible tiles: 2236994.00 (Alaska 400)\n",
      "Share of regions with capped tiles: 0.84\n",
      "Share of tiles with full overlap: 0.75\n",
      "Total number of tiles: 208802\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics on tiles \n",
    "meta_info = shapefile[SHAPEFILE_IDS]\n",
    "meta_info['num_eligible_squares'] = num_eligible_squares\n",
    "meta_info['count'] = num_used_squares\n",
    "tiles['full_overlap'] = (tiles['weight'] == 100).astype('int')\n",
    "overlap = tiles.groupby(SHAPEFILE_IDS, as_index=False).agg('mean')[SHAPEFILE_IDS + ['full_overlap']]\n",
    "meta_info = meta_info.merge(overlap, on=SHAPEFILE_IDS)\n",
    "meta_info.to_csv(DATA_OUTFOLDER + 'meta.csv', index=False)\n",
    "\n",
    "min_eligible_squares = meta_info.sort_values('num_eligible_squares', ascending=True).iloc[0]\n",
    "print(('Minimum eligible tiles: %.2f (' +  ' '.join([str(min_eligible_squares[key]) for key in SHAPEFILE_IDS]) \\\n",
    "      + ')') % min_eligible_squares['num_eligible_squares'])\n",
    "max_eligible_squares = meta_info.sort_values('num_eligible_squares', ascending=False).iloc[0]\n",
    "print(('Maximum eligible tiles: %.2f (' +  ' '.join([str(max_eligible_squares[key]) for key in SHAPEFILE_IDS]) \\\n",
    "      + ')') % max_eligible_squares['num_eligible_squares'])\n",
    "print('Share of regions with capped tiles: %.2f' % \\\n",
    "      (len(meta_info[meta_info['count'] == MAX_TILES_PER_REGION])/len(meta_info)))\n",
    "print('Share of tiles with full overlap: %.2f' % tiles['full_overlap'].mean())\n",
    "print('Total number of tiles: %i' % len(tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
