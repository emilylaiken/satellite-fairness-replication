{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. Satellite Featurizations Part 1 - Obtaining Tile Geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILES_FOLDER = '/data/mosaiks/replication/sampled_tiles/'\n",
    "SHAPEFILES_FOLDER = '/data/mosaiks/shapefiles/'\n",
    "MAX_TILES_PER_REGION = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR US\n",
    "SHAPEFILE_FNAME = SHAPEFILES_FOLDER + 'us_pumas/pumas.shp'\n",
    "SHAPEFILE_IDS = ['State', 'PUMA']\n",
    "DATA_OUTFOLDER = TILES_FOLDER + 'us/'\n",
    "PLOTS_OUTFOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR MEXICO\n",
    "SHAPEFILE_FNAME = '/data/mosaiks/shapefiles/mexico_municipalities.geojson'\n",
    "SHAPEFILE_IDS = ['municipality']\n",
    "DATA_OUTFOLDER = TILES_FOLDER + 'mexico/'\n",
    "PLOTS_OUTFOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR INDIA\n",
    "MAX_TILES_PER_REGION = 1000000000\n",
    "SHAPEFILE_FNAME = '/data/mosaiks/shrug/shrug.geojson'\n",
    "SHAPEFILE_IDS = ['shrid']\n",
    "DATA_OUTFOLDER = TILES_FOLDER + 'india/'\n",
    "PLOTS_OUTFOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL FOR DHS COUNTRIES\n",
    "dhs_country = 'peru' # change 'colombia' to each DHS country\n",
    "SHAPEFILE_FNAME = '/data/mosaiks/surveys/dhs/' + dhs_country + '_polygons.geojson'\n",
    "SHAPEFILE_IDS = ['cluster']\n",
    "DATA_OUTFOLDER = TILES_FOLDER + 'dhs/' + dhs_country + '/' \n",
    "PLOTS_OUTFOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in shapefile and format\n",
    "shapefile = gpd.read_file(SHAPEFILE_FNAME)\n",
    "shapefile = shapefile.to_crs(epsg=4326)\n",
    "shapefile['bounds'] = shapefile['geometry'].apply(lambda x: x.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.34% gridded...\r"
     ]
    }
   ],
   "source": [
    "# Get sampled MOSAIKS tiles for each region in the shapefile, along with degree of overlap\n",
    "num_eligible_squares = []\n",
    "num_used_squares = []\n",
    "tiles = []\n",
    "plot = False\n",
    "start = time.time()\n",
    "for i in range(len(shapefile)):\n",
    "    \n",
    "    print(('%.2f' % (100*i/len(shapefile))) + '% gridded...', end='\\r')\n",
    "    \n",
    "    # Get the region\n",
    "    region = shapefile.iloc[i]\n",
    "    region_info = gpd.GeoDataFrame(pd.DataFrame(region).T)\n",
    "    \n",
    "    # Get the bounding box for the region\n",
    "    min_latitude, max_latitude = region['bounds'][1], region['bounds'][3]\n",
    "    min_longitude, max_longitude = region['bounds'][0], region['bounds'][2]\n",
    "    \n",
    "    # Define the latitude/longitude grid of centroids\n",
    "    latitude_grid = (np.arange(round(min_latitude, 2)-.02, round(max_latitude, 2)+.02, .01) - .005)\n",
    "    longitude_grid = (np.arange(round(min_longitude, 2)-.02, round(max_longitude, 2)+.02, .01) - .005)\n",
    "    grid = np.meshgrid(latitude_grid, longitude_grid)\n",
    "    grid = np.array([grid[0].flatten(), grid[1].flatten()])\n",
    "    grid = pd.DataFrame(grid).T\n",
    "    grid.columns = ['Latitude', 'Longitude']\n",
    "    grid = gpd.GeoDataFrame(grid, geometry=gpd.points_from_xy(grid['Longitude'], grid['Latitude']), crs=4326)\n",
    "    \n",
    "    # Turn centroids into squares\n",
    "    squares = grid.copy()\n",
    "    squares['geometry'] = squares['geometry'].buffer(.005, cap_style=3)\n",
    "    \n",
    "    # Determine squares that have some overlap with the region\n",
    "    eligible_squares = gpd.sjoin(squares, region_info, how='inner', op='intersects')\n",
    "    num_eligible_squares.append(len(eligible_squares))\n",
    "    \n",
    "    # If more squares overlap with PUMA than we can process, take UAR sample of overlapping squares\n",
    "    if len(eligible_squares) > MAX_TILES_PER_REGION:\n",
    "        sampled_tiles = eligible_squares.sample(n=MAX_TILES_PER_REGION, replace=False, random_state=1)\n",
    "    else:\n",
    "        sampled_tiles = eligible_squares.copy()\n",
    "    \n",
    "    # Get weight for each tile (degree of overlap)\n",
    "    sampled_tiles['weight'] = sampled_tiles['geometry']\\\n",
    "        .apply(lambda x: 100*region['geometry'].buffer(0).intersection(x).area/x.area)\n",
    "    sampled_tiles_out = sampled_tiles[['Latitude', 'Longitude', 'weight'] + SHAPEFILE_IDS].dropna(how='any')\n",
    "    \n",
    "    num_used_squares.append(len(sampled_tiles_out))\n",
    "    \n",
    "    # Write to file\n",
    "    sampled_tiles_out.to_csv(DATA_OUTFOLDER + '/' + '_'.join([str(region[key]) for key in SHAPEFILE_IDS]), index=False)\n",
    "    \n",
    "    if PLOTS_OUTFOLDER is not None:\n",
    "        fig, ax = plt.subplots(1, figsize=(20, 20))\n",
    "        region_info.plot(ax=ax)\n",
    "        grid.plot(ax=ax, color='black', markersize=4)\n",
    "        squares.plot(ax=ax, color='lightgrey', alpha=.1, edgecolor='black')\n",
    "        eligible_squares.plot(ax=ax, color='grey', alpha=.3, edgecolor=None)\n",
    "        sampled_tiles.plot(ax=ax, color='grey', alpha=.5, edgecolor=None)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(' '.join([str(region[key]) for key in SHAPEFILE_IDS]), fontsize='xx-large')\n",
    "        plt.savefig(PLOTS_OUTFOLDER + '/' + '_'.join([str(region[key]) for key in SHAPEFILE_IDS]), dpi=300)\n",
    "\n",
    "print('Done gridding!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>weight</th>\n",
       "      <th>shrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>34.565</td>\n",
       "      <td>73.945</td>\n",
       "      <td>11.023195</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.575</td>\n",
       "      <td>73.945</td>\n",
       "      <td>9.476737</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34.555</td>\n",
       "      <td>73.955</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>34.565</td>\n",
       "      <td>73.955</td>\n",
       "      <td>67.110886</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>34.575</td>\n",
       "      <td>73.955</td>\n",
       "      <td>49.945180</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34.555</td>\n",
       "      <td>73.965</td>\n",
       "      <td>72.883681</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34.565</td>\n",
       "      <td>73.965</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>34.575</td>\n",
       "      <td>73.965</td>\n",
       "      <td>44.278274</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>34.555</td>\n",
       "      <td>73.975</td>\n",
       "      <td>51.033009</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>34.565</td>\n",
       "      <td>73.975</td>\n",
       "      <td>72.138502</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>34.575</td>\n",
       "      <td>73.975</td>\n",
       "      <td>17.453933</td>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude      weight                   shrid\n",
       "20    34.565     73.945   11.023195  11-01-001-00001-000005\n",
       "21    34.575     73.945    9.476737  11-01-001-00001-000005\n",
       "27    34.555     73.955    0.378521  11-01-001-00001-000005\n",
       "28    34.565     73.955   67.110886  11-01-001-00001-000005\n",
       "29    34.575     73.955   49.945180  11-01-001-00001-000005\n",
       "35    34.555     73.965   72.883681  11-01-001-00001-000005\n",
       "36    34.565     73.965  100.000000  11-01-001-00001-000005\n",
       "37    34.575     73.965   44.278274  11-01-001-00001-000005\n",
       "43    34.555     73.975   51.033009  11-01-001-00001-000005\n",
       "44    34.565     73.975   72.138502  11-01-001-00001-000005\n",
       "45    34.575     73.975   17.453933  11-01-001-00001-000005"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_tiles_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525868"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_eligible_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all tiles together, write to files partitioned for MOSAIKS API\n",
    "tiles = []\n",
    "for fname in os.listdir(DATA_OUTFOLDER):\n",
    "    if fname[0] != '.':\n",
    "        tiles.append(pd.read_csv(DATA_OUTFOLDER + '/' + fname))\n",
    "tiles = pd.concat(tiles)\n",
    "tiles = tiles[['Latitude', 'Longitude', 'weight'] + SHAPEFILE_IDS]\n",
    "tiles.to_csv(DATA_OUTFOLDER + '/sampled_tiles.csv', index=False, float_format='%.3f')\n",
    "tiles_with_duplicates = pd.read_csv(DATA_OUTFOLDER + '/sampled_tiles.csv')\n",
    "tiles = tiles_with_duplicates.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "partitions = list(np.arange(0, len(tiles), 100000)) + [len(tiles)]\n",
    "for i in range(len(partitions)-1):\n",
    "    tiles[partitions[i]:partitions[i+1]]\\\n",
    "        .to_csv(DATA_OUTFOLDER + 'sampled_tiles_partition_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for shrug, look at all sampled files. \n",
    "# because there are so many tiles, we sent sampled_tiles_unique.csv to the API maintainers directly\n",
    "# but also could have chunked this one and used the API like we did for the other regions\n",
    "if SHAPEFILE_IDS[0] == 'shrid':\n",
    "    unique_tiles = pd.DataFrame(np.unique(tiles[['Latitude','Longitude']],axis=0))\n",
    "    unique_tiles.to_csv(DATA_OUTFOLDER + 'sampled_tiles_unique.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum eligible tiles: 14.00 (11-08-117-00592-800554)\n",
      "Maximum eligible tiles: 255.00 (11-28-541-04740-802935)\n",
      "Share of regions with capped tiles: 0.00\n",
      "Share of tiles with full overlap: 0.37\n",
      "Total number of tiles: 5334\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics on tiles \n",
    "meta_info = shapefile[SHAPEFILE_IDS]\n",
    "meta_info['num_eligible_squares'] = num_eligible_squares\n",
    "meta_info['count'] = num_used_squares\n",
    "tiles['full_overlap'] = (tiles['weight'] == 100).astype('int')\n",
    "overlap = tiles.groupby(SHAPEFILE_IDS, as_index=False).agg('mean')[SHAPEFILE_IDS + ['full_overlap']]\n",
    "meta_info = meta_info.merge(overlap, on=SHAPEFILE_IDS)\n",
    "meta_info.to_csv(DATA_OUTFOLDER + 'meta.csv', index=False)\n",
    "\n",
    "min_eligible_squares = meta_info.sort_values('num_eligible_squares', ascending=True).iloc[0]\n",
    "print(('Minimum eligible tiles: %.2f (' +  ' '.join([str(min_eligible_squares[key]) for key in SHAPEFILE_IDS]) \\\n",
    "      + ')') % min_eligible_squares['num_eligible_squares'])\n",
    "max_eligible_squares = meta_info.sort_values('num_eligible_squares', ascending=False).iloc[0]\n",
    "print(('Maximum eligible tiles: %.2f (' +  ' '.join([str(max_eligible_squares[key]) for key in SHAPEFILE_IDS]) \\\n",
    "      + ')') % max_eligible_squares['num_eligible_squares'])\n",
    "print('Share of regions with capped tiles: %.2f' % \\\n",
    "      (len(meta_info[meta_info['count'] == MAX_TILES_PER_REGION])/len(meta_info)))\n",
    "print('Share of tiles with full overlap: %.2f' % tiles['full_overlap'].mean())\n",
    "print('Total number of tiles: %i' % len(tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
