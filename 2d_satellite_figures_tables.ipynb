{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c. Satellite featurizations part 3 -- Satellite-related figures and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import config\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "#from numba import jit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table S1: Summary of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILES_FOLDER = '/data/mosaiks/replication/sampled_tiles/'\n",
    "\n",
    "save_fig = False\n",
    "fig_dir = 'figs/fairsiml_figs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "\n",
    "for country in ['us', 'mexico', 'dhs/colombia', 'dhs/honduras', 'dhs/indonesia', 'dhs/kenya', 'dhs/nigeria', \n",
    "                'dhs/peru','dhs/philippines', 'india']:#, 'us',]: #'india']:\n",
    "    \n",
    "    if country == 'mexico':\n",
    "        survey = pd.read_csv('/data/mosaiks/replication/surveys/' + country + '/grouped.csv')\n",
    "        meta = pd.read_csv(TILES_FOLDER + country + '/meta.csv')\n",
    "    elif country == 'india':\n",
    "        survey = pd.read_csv('/data/mosaiks/replication/surveys/' + country + '/grouped.csv')\n",
    "        meta = pd.read_csv(TILES_FOLDER + country + '/shrug_condensed_regions_25_max_tiles_100_meta.csv')\n",
    "    elif country == 'us':\n",
    "        survey = pd.read_csv('/data/mosaiks/replication/surveys/' + country + '/groundtruth_by_puma_2019.csv')\n",
    "        meta = pd.read_csv(TILES_FOLDER + country + '/meta.csv')\n",
    "    else:\n",
    "        survey = pd.read_csv('/data/mosaiks/replication/surveys/' + country + '_grouped.csv')\n",
    "        meta = pd.read_csv(TILES_FOLDER + country + '/meta.csv')\n",
    "        \n",
    "        \n",
    "    table.append([country, len(survey), '%.2f' % (100*survey['rural'].mean()), meta['count'].min(), \n",
    "                  '%.2f' % meta['count'].mean(), meta['count'].max()])\n",
    "table = pd.DataFrame(table)\n",
    "table.columns = ['Country', 'Regions', '% Rural', 'Min. Tiles', 'Mean Tiles', 'Max Tiles']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average dist by urban and rural\n",
    "\n",
    "def barplot_dists(mean_dfs, stderr_dfs, all_country_names, ax = None,\n",
    "                 title='average distance between pairs of MOSAIKS features'):\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        \n",
    "    n_countries = len(all_country_names)\n",
    "\n",
    "    ax.bar(np.arange(n_countries)-.25, mean_dfs['Rural-Rural'], label= 'Rural-Rural', color='indianred', width = 0.2)\n",
    "    ax.bar(np.arange(n_countries), mean_dfs['Urban-Urban'], label= 'Urban-Urban', color='steelblue', width = 0.2)\n",
    "    ax.bar(np.arange(n_countries)+.25, mean_dfs['Urban-Rural'], label= 'Urban-Rural',color='yellowgreen', width = 0.2)\n",
    "\n",
    "    ax.errorbar(np.arange(n_countries)-.25, mean_dfs['Rural-Rural'], \n",
    "                yerr=2*stderr_dfs['Rural-Rural'], fmt=\"none\", color=\"black\",capsize=2)\n",
    "    ax.errorbar(np.arange(n_countries), mean_dfs['Urban-Urban'], \n",
    "                yerr=2*stderr_dfs['Urban-Urban'], fmt=\"none\", color=\"black\",capsize=2)\n",
    "    ax.errorbar(np.arange(n_countries)+.25, mean_dfs['Urban-Rural'], \n",
    "               yerr=2*stderr_dfs['Urban-Rural'], fmt=\"none\", color=\"black\",capsize=2)\n",
    "\n",
    "\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_xticks(np.arange(n_countries)+.2)\n",
    "    ax.set_xticklabels([x.title() for x in all_country_names], rotation=30, ha='right')\n",
    "    ax.set_ylabel(r'avg. $\\ell_2$ distance ')\n",
    "    ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "def clean_plot(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    plt.tight_layout\n",
    "    \n",
    "@jit\n",
    "def slow_dist(X):\n",
    "    out = np.zeros((X.shape[0],X.shape[0]))\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        for j in range(i+1,len(X)):\n",
    "            dist = np.sqrt(np.sum((X[i] - X[j])**2))\n",
    "            out[i,j] = dist\n",
    "            out[j,i] = dist\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config.dataset_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratios = []\n",
    "dists_by_urban_rural_all = []\n",
    "\n",
    "pcas = []\n",
    "rurals = []\n",
    "\n",
    "dhs_country_names = ['colombia', \n",
    "                             'honduras', \n",
    "                             'indonesia', \n",
    "                             'nigeria', \n",
    "                             'kenya', \n",
    "                             'peru', \n",
    "                             'philippines']\n",
    "\n",
    "other_country_names = ['US','Mexico', 'India']\n",
    "\n",
    "all_country_names = np.sort([x.lower() for x in dhs_country_names + other_country_names])\n",
    "print(all_country_names)\n",
    "\n",
    "\n",
    "for c,country in enumerate(all_country_names):\n",
    "    \n",
    "    # 1. read in data\n",
    "    if country.lower() in ['us', 'mexico', 'india_nl', 'india']:\n",
    "        cfg_this = cfg[country.lower()]\n",
    "        features_fname = cfg_this['FEATURES_FNAME']\n",
    "        labels_fname = cfg_this['LABELS_FNAME']\n",
    "    else:   \n",
    "        cfg_this = cfg['dhs']\n",
    "        features_fname = cfg_this['FEATURES_FNAME'](country)\n",
    "        labels_fname = cfg_this['LABELS_FNAME'](country)\n",
    "    \n",
    "    merge_keys = cfg_this['MERGE_KEYS']\n",
    "    pov_key = cfg_this['POVERTY']\n",
    "    print(features_fname)\n",
    "    \n",
    "    feats_df = pd.read_csv(features_fname)\n",
    "    rural_df = pd.read_csv(labels_fname, low_memory=False)[merge_keys+['rural',pov_key]]\n",
    "    df = pd.merge(feats_df, rural_df, how='inner', on=merge_keys)\n",
    "\n",
    "    # subset india because it's so big\n",
    "    # note: this means India will look different each time in this plot\n",
    "    if country.lower() == 'india':\n",
    "        n_instances_per_group_india = 2000\n",
    "        df = df.groupby('rural', group_keys=False).apply(lambda x: x.sample(n_instances_per_group_india, \n",
    "                                                                            replace=False))\n",
    "\n",
    "        \n",
    "    nfeats = 4000\n",
    "    feat_cols = [f'Feature{x}' for x in range(nfeats)]\n",
    "    pov = df[pov_key]\n",
    "\n",
    "    X = np.array(df.loc[:,feat_cols])\n",
    "    rural = np.array(df['rural']).astype(int)\n",
    "    \n",
    "    # 2. compute distance between all points\n",
    "    t1 = time.time()\n",
    "    dists = slow_dist(X)\n",
    "    t2 = time.time()\n",
    "    print(f'{t2-t1:.2f} seconds')\n",
    "    \n",
    "    # 3. average distances by urban and rural\n",
    "    dists_by_urban_rural = {'00':[],\n",
    "                            '01':[],\n",
    "                            '10':[],\n",
    "                            '11':[]}\n",
    "    \n",
    "    # count all pairs\n",
    "    for i in range(len(X)):\n",
    "        for j in range(i+1, len(X)):\n",
    "            ur_key = f'{rural[i]}{rural[j]}'\n",
    "            dists_by_urban_rural[ur_key].append(dists[i,j])\n",
    "    \n",
    "    # urban rural pairs are e\n",
    "    dists_ur = {'rural_rural': dists_by_urban_rural['11'],\n",
    "                'urban_urban': dists_by_urban_rural['00'],\n",
    "                'mixed': dists_by_urban_rural['01'] + dists_by_urban_rural['10']\n",
    "               }\n",
    "    \n",
    "    dists_by_urban_rural_all.append(dists_ur)\n",
    "    \n",
    "\n",
    "    print(country)\n",
    " \n",
    "    # plot pca dimension reduction by urban rural\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca_2 = pca.fit_transform(X)\n",
    "    pcas.append(X_pca_2)\n",
    "    rurals.append(rural)\n",
    "    explained_variance_ratios.append(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Country', 'Rural-Rural', 'Urban-Urban','Urban-Rural']\n",
    "mean_dfs = []\n",
    "stderr_dfs = []\n",
    "\n",
    "def compute_se(x):\n",
    "    return np.std(x) / np.sqrt(len(x))\n",
    "\n",
    "for c,country in enumerate(all_country_names):\n",
    "    mean_dfs.append(pd.DataFrame([[country.capitalize(),\n",
    "                              np.mean(dists_by_urban_rural_all[c]['rural_rural']),\n",
    "                              np.mean(dists_by_urban_rural_all[c]['urban_urban']),\n",
    "                              np.mean(dists_by_urban_rural_all[c]['mixed']),\n",
    "                                                ]],\n",
    "                           columns = cols))\n",
    "    \n",
    "    stderr_dfs.append(pd.DataFrame([[country.capitalize(),\n",
    "                                      compute_se(dists_by_urban_rural_all[c]['rural_rural']),\n",
    "                                      compute_se(dists_by_urban_rural_all[c]['urban_urban']),\n",
    "                                      compute_se(dists_by_urban_rural_all[c]['mixed']),\n",
    "                                                ]],\n",
    "                           columns = cols))\n",
    "    \n",
    "mean_dfs_all = pd.concat(mean_dfs).sort_values(by='Country')\n",
    "stderr_dfs_all = pd.concat(stderr_dfs).sort_values(by='Country')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_shuffle_instances(to_shuffle, seed=0):\n",
    "    rs = np.random.RandomState(0)\n",
    "    n = len(to_shuffle[0])\n",
    "    idxs = rs.choice(n,n,replace=False)\n",
    "    \n",
    "    return [x[idxs] for x in to_shuffle]\n",
    "\n",
    "\n",
    "\n",
    "def plot_pca(X_pca, \n",
    "             rurals, \n",
    "             palette = {0: 'steelblue', 1:'indianred'},\n",
    "             kwargs = {'alpha':0.4},\n",
    "             ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    ax.scatter(X_pca[:,0],X_pca[:,1],\n",
    "               c=[palette[x] for x in rurals],\n",
    "               **kwargs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_country_names = [str(x) for x in all_country_names]\n",
    "all_country_names[-1] = 'united states'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.3, style='whitegrid')\n",
    "\n",
    "\n",
    "gs_kw = dict(width_ratios=[5,] + [1]*5,height_ratios = [1,1])\n",
    "figsize = (28, 8)\n",
    "fig, axd = plt.subplot_mosaic([['barplot',] + [f'pca_{i}' for i in range(5)],\n",
    "                               ['barplot',] + [f'pca_{i}' for i in range(5,10)]],\n",
    "                               gridspec_kw=gs_kw,\n",
    "                               figsize=figsize,)\n",
    "\n",
    "\n",
    "barplot_dists(mean_dfs_all, stderr_dfs_all, all_country_names=all_country_names, \n",
    "              ax=axd['barplot'],\n",
    "              title=None\n",
    "              #r'$\\bf{(A)}$ average distance between pairs of MOSAIKS features'\n",
    "             )\n",
    "\n",
    "for c,country in enumerate(all_country_names): \n",
    "    axc = axd[f'pca_{c}']    \n",
    "    [X_pca_shuffled, rurals_shuffled] = co_shuffle_instances([pcas[c],rurals[c]])\n",
    "    \n",
    "    plot_pca(X_pca_shuffled, rurals_shuffled, ax=axc)\n",
    "\n",
    "\n",
    "for c in range(len(all_country_names)):\n",
    "    axc = axd[f'pca_{c}']\n",
    "    if c % 5 != 0:\n",
    "        axc.set_yticklabels('')\n",
    "    if c < 5:\n",
    "        axc.set_xticklabels('')\n",
    "        \n",
    "    if c % 5 == 0: \n",
    "        axc.set_ylabel('Features PCA dim. 2')\n",
    "        axd['pca_0'].set_ylabel('Features PCA dim. 2') \n",
    "    \n",
    "    if c >= 5:\n",
    "        axc.set_xlabel('Features PCA dim. 1')\n",
    "        \n",
    "    axc.set_xlim(-60,100)\n",
    "    axc.set_ylim(-40,60)\n",
    "    \n",
    "    axc.set_title(all_country_names[c].capitalize(), fontsize=12)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f'{fig_dir}/Figure_2.png',dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(explained_variance_ratios).sum(axis=1).min().round(3))\n",
    "print(np.array(explained_variance_ratios).sum(axis=1).max().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_countries = ['colombia',  'honduras', 'indonesia', 'nigeria', 'kenya', 'peru', 'philippines']\n",
    "all_countries = np.sort(dhs_countries + ['us', 'mexico', 'india'])\n",
    "countries_one_tile = all_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_one_tile = all_countries\n",
    "dists_by_urban_rural_all_one_tile = []\n",
    "rurals_one_tile = []\n",
    "\n",
    "for c,country in enumerate(countries_one_tile):\n",
    "    \n",
    "    \n",
    "    # 1. read in data\n",
    "    if country.lower() in ['us', 'mexico', 'india_nl', 'india']:\n",
    "        cfg_this = cfg[country.lower()]\n",
    "        features_fname = cfg_this['FEATURES_FNAME']\n",
    "        labels_fname = cfg_this['LABELS_FNAME']\n",
    "    else:   \n",
    "        cfg_this = cfg['dhs']\n",
    "        features_fname = cfg_this['FEATURES_FNAME'](country)\n",
    "        labels_fname = cfg_this['LABELS_FNAME'](country)\n",
    "    \n",
    "    features_fname = features_fname.replace('features/','features_1_tile_per_region/')\n",
    "    if 'india' in country.lower():\n",
    "        features_fname = features_fname.replace('max_tiles_100','max_tiles_1')\n",
    "    merge_keys = cfg_this['MERGE_KEYS']\n",
    "    pov_key = cfg_this['POVERTY']\n",
    "    print(features_fname)\n",
    "    \n",
    "    \n",
    "    \n",
    "    feats_df = pd.read_csv(features_fname)\n",
    "    rural_df = pd.read_csv(labels_fname, low_memory=False)[merge_keys+['rural',pov_key]]\n",
    "    \n",
    "    df = pd.merge(feats_df, rural_df, how='inner', on=merge_keys)\n",
    "    # subset india because it's so big\n",
    "    if country.lower() == 'india':\n",
    "        n_instances_per_group_india = 2000\n",
    "        df = df.groupby('rural', group_keys=False).apply(lambda x: x.sample(n_instances_per_group_india, \n",
    "                                                                       replace=False))\n",
    "\n",
    "    nfeats = 4000\n",
    "    feat_cols = [f'Feature{x}' for x in range(nfeats)]\n",
    "    pov = df[pov_key]\n",
    "\n",
    "    X = np.array(df.loc[:,feat_cols])\n",
    "    rural = np.array(df['rural']).astype(int)\n",
    "    \n",
    "    print(f'{country}: {len(df)} ({rural.sum()} rural), {len(rural)- rural.sum()} urban)')\n",
    "\n",
    "    \n",
    "    # 2. compute distance between all points\n",
    "    t1 = time.time()\n",
    "    dists = slow_dist(X)\n",
    "    t2 = time.time()\n",
    "    print(f'{t2-t1:.2f} seconds')\n",
    "    \n",
    "    # 3. average distances by urban and rural\n",
    "    dists_by_urban_rural = {'00':[],\n",
    "                            '01':[],\n",
    "                            '10':[],\n",
    "                            '11':[]}\n",
    "    \n",
    "    # count all pairs\n",
    "    for i in range(len(X)):\n",
    "        for j in range(i+1, len(X)):\n",
    "            ur_key = f'{rural[i]}{rural[j]}'\n",
    "            dists_by_urban_rural[ur_key].append(dists[i,j])\n",
    "            \n",
    "    dists_ur = {'rural_rural': dists_by_urban_rural['11'],\n",
    "                'urban_urban': dists_by_urban_rural['00'],\n",
    "                'mixed': dists_by_urban_rural['01'] + dists_by_urban_rural['10']\n",
    "               }\n",
    "    \n",
    "    dists_by_urban_rural_all_one_tile.append(dists_ur)\n",
    "    rurals_one_tile.append(rural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Country', 'Rural-Rural', 'Urban-Urban','Urban-Rural']\n",
    "mean_dfs_1 = []\n",
    "stderr_dfs_1 = []\n",
    "\n",
    "def compute_se(x):\n",
    "    return np.std(x) / np.sqrt(len(x))\n",
    "\n",
    "for c,country in enumerate(countries_one_tile):\n",
    "    mean_dfs_1.append(pd.DataFrame([[country.capitalize(),\n",
    "                              np.mean(dists_by_urban_rural_all_one_tile[c]['rural_rural']),\n",
    "                              np.mean(dists_by_urban_rural_all_one_tile[c]['urban_urban']),\n",
    "                              np.mean(dists_by_urban_rural_all_one_tile[c]['mixed']),\n",
    "                                                ]],\n",
    "                           columns = cols))\n",
    "    \n",
    "    stderr_dfs_1.append(pd.DataFrame([[country.capitalize(),\n",
    "                                      compute_se(dists_by_urban_rural_all_one_tile[c]['rural_rural']),\n",
    "                                      compute_se(dists_by_urban_rural_all_one_tile[c]['urban_urban']),\n",
    "                                      compute_se(dists_by_urban_rural_all_one_tile[c]['mixed']),\n",
    "                                                ]],\n",
    "                           columns = cols))\n",
    "    \n",
    "mean_dfs_1 = pd.concat(mean_dfs_1).sort_values(by='Country')\n",
    "stderr_dfs_1 = pd.concat(stderr_dfs_1).sort_values(by='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2, style='whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "barplot_dists(mean_dfs_1, stderr_dfs_1, all_country_names=countries_one_tile, ax=ax)\n",
    "\n",
    "ax.set_title('average distance between pairs of MOSAIKS features (single tile per region)')\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f'{fig_dir}/dist_between_feats_1_tile_per_region.png',dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siml",
   "language": "python",
   "name": "siml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
