{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import shrug_processing\n",
    "from importlib import reload\n",
    "from shrug_processing import merge_raw_shrug_files, prepare_shrug_data_for_geom, split_urban_rural\n",
    "\n",
    "import shrid_aggregation\n",
    "from shrid_aggregation import loop_over_states\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook processes shrug data into the shapefiles ready for downstream analysis.\n",
    "\n",
    "shrug_stats.dta and shrid2.gpkg are the files that Paul Novosad shared directly with us via email. He said public version would be released (as of Sep 2022). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at what threshold to merge rural regions until -- we tried 14 (median area of rural regions) and 25\n",
    "sq_km_thresh= 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. process the raw data and shapefiles into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/mosaiks/shrug/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26422 entries dropped for not having consumption value\n",
      "525868 entries remaining\n",
      "for the 126 shrids with urban and rural, consumption  is a weighted average of urban and rural consumption, weighted by urban and rural population counts.\n",
      "saving compiled data in /data/mosaiks/shrug/shrug.csv\n",
      "saving geo compiled data in /data/mosaiks/shrug/shrug.geojson\n"
     ]
    }
   ],
   "source": [
    "data_fp = os.path.join(data_dir,'shrug_stats.dta')\n",
    "shapefile_fp = os.path.join(data_dir,'shrid2.gpkg')\n",
    "merge_raw_shrug_files(data_fp, shapefile_fp, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrid</th>\n",
       "      <th>pc11_pca_tot_p</th>\n",
       "      <th>shrid_pc11_pca_tot_p_r</th>\n",
       "      <th>shrid_pc11_pca_tot_p_u</th>\n",
       "      <th>ec13_emp_all</th>\n",
       "      <th>ec13_emp_manuf</th>\n",
       "      <th>secc_cons_pc_rural</th>\n",
       "      <th>secc_pov_rate_rural</th>\n",
       "      <th>secc_pov_rate_urban</th>\n",
       "      <th>secc_cons_pc_urban</th>\n",
       "      <th>...</th>\n",
       "      <th>pc11_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rural</th>\n",
       "      <th>urban</th>\n",
       "      <th>secc_cons_pc_combined</th>\n",
       "      <th>pc11_pca_tot_p_combined</th>\n",
       "      <th>frac_rural</th>\n",
       "      <th>frac_urban</th>\n",
       "      <th>state</th>\n",
       "      <th>dummy_ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-01-001-00001-000002</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13509.517578</td>\n",
       "      <td>0.477891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POLYGON ((73.83561696 34.55965044, 73.82536307...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13509.517578</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-01-001-00001-000005</td>\n",
       "      <td>5255.0</td>\n",
       "      <td>5255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8611.757812</td>\n",
       "      <td>0.776421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>POLYGON ((73.94628924 34.5699081, 73.94711292 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8611.757812</td>\n",
       "      <td>5255.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    shrid  pc11_pca_tot_p  shrid_pc11_pca_tot_p_r  \\\n",
       "0  11-01-001-00001-000002          3770.0                  3770.0   \n",
       "1  11-01-001-00001-000005          5255.0                  5255.0   \n",
       "\n",
       "   shrid_pc11_pca_tot_p_u  ec13_emp_all  ec13_emp_manuf  secc_cons_pc_rural  \\\n",
       "0                     NaN          49.0             0.0        13509.517578   \n",
       "1                     NaN          82.0             9.0         8611.757812   \n",
       "\n",
       "   secc_pov_rate_rural  secc_pov_rate_urban  secc_cons_pc_urban  ...  pc11_id  \\\n",
       "0             0.477891                  NaN                 NaN  ...      2.0   \n",
       "1             0.776421                  NaN                 NaN  ...      5.0   \n",
       "\n",
       "                                            geometry  rural  urban  \\\n",
       "0  POLYGON ((73.83561696 34.55965044, 73.82536307...   True  False   \n",
       "1  POLYGON ((73.94628924 34.5699081, 73.94711292 ...   True  False   \n",
       "\n",
       "   secc_cons_pc_combined  pc11_pca_tot_p_combined  frac_rural  frac_urban  \\\n",
       "0           13509.517578                   3770.0         1.0         0.0   \n",
       "1            8611.757812                   5255.0         1.0         0.0   \n",
       "\n",
       "   state  dummy_ones  \n",
       "0      1         1.0  \n",
       "1      1         1.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output csv \n",
    "shrug_csv_fp = f'{data_dir}/shrug.csv'\n",
    "all_df = pd.read_csv(os.path.join(data_dir,'shrug.csv'))\n",
    "all_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. combine small rural shapefiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_condensed = data_dir+'shrug_condensed_geoms'\n",
    "if not os.path.exists(data_dir_condensed):\n",
    "    os.mkdir(data_dir_condensed)\n",
    "    print(data_dir_condensed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3524 urban shrids\n",
      "there are 522344 rural shrids before merging\n",
      "median area of urban regions: 13.919551831449446 km^2\n"
     ]
    }
   ],
   "source": [
    "# load gdf and add projected area\n",
    "gdf_by_shrid = prepare_shrug_data_for_geom(shrug_csv_fp)\n",
    "\n",
    "# separate urban and rural gdfs\n",
    "gdfs_split = split_urban_rural(gdf_by_shrid)\n",
    "gdf_urban = gdfs_split['gdf_urban']\n",
    "gdf_rural = gdfs_split['gdf_rural']\n",
    "\n",
    "print(f'there are {len(gdf_urban)} urban shrids')\n",
    "print(f'there are {len(gdf_rural)} rural shrids before merging')\n",
    "print(f'median area of urban regions: {np.median(gdf_urban.proj_area) / 1e6} km^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median area of urban regions: 2.919125231763903 km^2\n"
     ]
    }
   ],
   "source": [
    "print(f'median area of urban regions: {np.median(gdf_rural.proj_area) / 1e6} km^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_file_dir = os.path.join(data_dir_condensed,f'thresh_{sq_km_thresh}_sq_km')\n",
    "if not os.path.exists(chunked_file_dir):\n",
    "    os.mkdir(chunked_file_dir)\n",
    "    print('making dir: ',chunked_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_urban.to_file(os.path.join(data_dir_condensed,'shrug_urban.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 loop over states in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_01.geojson\n",
      "state 01 took 0.47 minutes\n",
      "02\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_02.geojson\n",
      "state 02 took 2.97 minutes\n",
      "03\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_03.geojson\n",
      "state 03 took 1.03 minutes\n",
      "05\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_05.geojson\n",
      "state 05 took 2.19 minutes\n",
      "06\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_06.geojson\n",
      "state 06 took 0.37 minutes\n",
      "08\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_08.geojson\n",
      "state 08 took 2.26 minutes\n",
      "09\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_09.geojson\n",
      "state 09 took 4.76 minutes\n",
      "10\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_10.geojson\n",
      "state 10 took 2.58 minutes\n",
      "11\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_11.geojson\n",
      "state 11 took 0.09 minutes\n",
      "14\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_14.geojson\n",
      "state 14 took 0.09 minutes\n",
      "16\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_16.geojson\n",
      "state 16 took 0.14 minutes\n",
      "17\n",
      "df for state 17 of length 1; writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_17.geojson\n",
      "18\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_18.geojson\n",
      "state 18 took 1.16 minutes\n",
      "19\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_19.geojson\n",
      "state 19 took 8.41 minutes\n",
      "20\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_20.geojson\n",
      "state 20 took 1.81 minutes\n",
      "21\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_21.geojson\n",
      "state 21 took 3.22 minutes\n",
      "22\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_22.geojson\n",
      "state 22 took 1.33 minutes\n",
      "23\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_23.geojson\n",
      "state 23 took 2.13 minutes\n",
      "24\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_24.geojson\n",
      "state 24 took 1.12 minutes\n",
      "25\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_25.geojson\n",
      "state 25 took 0.03 minutes\n",
      "27\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_27.geojson\n",
      "state 27 took 1.85 minutes\n",
      "28\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_28.geojson\n",
      "state 28 took 1.39 minutes\n",
      "29\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_29.geojson\n",
      "state 29 took 1.70 minutes\n",
      "30\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_30.geojson\n",
      "state 30 took 0.11 minutes\n",
      "33\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_33.geojson\n",
      "state 33 took 0.99 minutes\n",
      "34\n",
      "writing to /data/mosaiks/shrug/shrug_condensed_geoms/thresh_25_sq_km/shrug_rural_state_34.geojson\n",
      "state 34 took 0.05 minutes\n"
     ]
    }
   ],
   "source": [
    "# this is the loop that takes a while.\n",
    "loop_over_states(gdf_rural, \n",
    "                 sq_km_thresh, \n",
    "                 chunked_file_dir, \n",
    "                 num_threads=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Read in the separate chunked files and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of 27: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n",
      "same number of original shrids after merged? True\n"
     ]
    }
   ],
   "source": [
    "states_rural = np.sort(gdf_rural.state.unique())\n",
    "# read in and compile\n",
    "\n",
    "fps = [os.path.join(data_dir_condensed,'shrug_urban.geojson')] +\\\n",
    "      [os.path.join(chunked_file_dir,f'shrug_rural_state_{state}.geojson') for state in states_rural] \n",
    "      \n",
    "\n",
    "dfs_by_state  = []\n",
    "print(f'of {len(fps)}: ', end = '')\n",
    "for i,fp in enumerate(fps):\n",
    "    print(f'{i} ', end = '')\n",
    "    df_by_state = gpd.read_file(fp)\n",
    "    if fp.endswith('shrug_urban.geojson'):\n",
    "        df_by_state['region'] = df_by_state['shrid'].apply(lambda x: x.split('-')[2])\n",
    "    dfs_by_state.append(df_by_state.to_crs(epsg=4326))\n",
    "print()\n",
    "\n",
    "# concatenate results by state\n",
    "shrug_condensed = pd.concat(dfs_by_state).reset_index(drop=True)\n",
    "# put in the shrids_merged_str value for the urban shrids\n",
    "shrug_condensed.loc[shrug_condensed.urban==True,'shrids_merged_str'] = shrug_condensed[shrug_condensed.urban].shrid\n",
    "\n",
    "# perform some checks\n",
    "\n",
    "# make sure all shrids are used by evaluating if there are the same number of unique shrids\n",
    "num_ids_per_row = shrug_condensed.shrids_merged_str.apply(lambda x: len(x.split(',')))\n",
    "print(f'same number of original shrids after merged? {(sum(num_ids_per_row) == len(gdf_by_shrid))}')\n",
    "\n",
    "# assign rural to places with no urban\n",
    "shrug_condensed.rename(columns={'rural':'has_rural',\n",
    "                                'urban':'has_urban'},inplace=True)\n",
    "shrug_condensed.loc[:,'rural'] = ~ shrug_condensed.loc[:,'has_urban'] \n",
    "\n",
    "# make new id and dicts explaining the relationships\n",
    "shrug_condensed['condensed_shrug_id'] = np.arange(len(shrug_condensed))\n",
    "\n",
    "# save output\n",
    "shrug_condensed.to_file(os.path.join(data_dir,\n",
    "                                     f'shrug_condensed_regions_{sq_km_thresh}.geojson'),driver='GeoJSON')\n",
    "shrug_condensed.drop('geometry',axis=1).to_csv(os.path.join(data_dir,\n",
    "                                     f'shrug_condensed_regions_{sq_km_thresh}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 63356 total shrids after merging\n",
      "there are 3524 urban shrids after merging\n",
      "there are 59832 rural shrids after merging\n"
     ]
    }
   ],
   "source": [
    "# if you want to just load the preloaded one:\n",
    "#shrug_condensed = gpd.read_file(os.path.join(data_dir,\n",
    "#                                f'shrug_condensed_regions_{sq_km_thresh}.geojson'))\n",
    "\n",
    "print(f'there are {len(shrug_condensed)} total shrids after merging')\n",
    "print(f'there are {sum(~shrug_condensed[\"rural\"])} urban shrids after merging')\n",
    "print(f'there are {sum(shrug_condensed[\"rural\"])} rural shrids after merging')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Make and save dictionaries explaining the relationship between condensed shrids and original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_to_shrids = {}\n",
    "for key, val in zip(shrug_condensed['condensed_shrug_id'], \n",
    "                    shrug_condensed.shrids_merged_str.apply(lambda x: x.split(','))):\n",
    "    new_id_to_shrids[key] = val\n",
    "\n",
    "shrids_to_new_id = {}\n",
    "\n",
    "for new_id, shrids_this_id in zip(shrug_condensed['condensed_shrug_id'], \n",
    "                    shrug_condensed.shrids_merged_str.apply(lambda x: x.split(','))):\n",
    "\n",
    "    for shrid in shrids_this_id:\n",
    "        shrids_to_new_id[shrid] = new_id\n",
    "    \n",
    "# save jsons\n",
    "json.dump(shrids_to_new_id, open(os.path.join(data_dir,f'shrids_to_condensed_ids_{sq_km_thresh}.json'), 'w' ) )\n",
    "json.dump(new_id_to_shrids, open(os.path.join(data_dir,f'condensed_ids_to_shrids_{sq_km_thresh}.json'), 'w' ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siml",
   "language": "python",
   "name": "siml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
